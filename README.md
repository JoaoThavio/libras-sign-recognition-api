# ğŸ¤Ÿ Libras Sign Recognition API

API para reconhecimento de sinais do alfabeto em Libras utilizando VisÃ£o Computacional e Machine Learning.

O sistema captura a imagem da webcam, detecta a mÃ£o com MediaPipe, extrai os pontos da mÃ£o (landmarks) e utiliza um modelo treinado com Scikit-Learn para classificar a letra correspondente.  
O resultado Ã© disponibilizado atravÃ©s de uma API REST construÃ­da com FastAPI.

---

## ğŸ“Œ Arquitetura


Webcam
â†“
OpenCV
â†“
MediaPipe (Hand Tracking)
â†“
ExtraÃ§Ã£o de Landmarks
â†“
Modelo Machine Learning (Scikit-Learn)
â†“
FastAPI
â†“
Resposta JSON


---

## ğŸš€ Tecnologias Utilizadas

| Tecnologia      | Finalidade |
|---------------|------------|
| Python 3.10+  | Linguagem principal |
| OpenCV        | Captura de vÃ­deo |
| MediaPipe     | DetecÃ§Ã£o e rastreamento das mÃ£os |
| NumPy         | ManipulaÃ§Ã£o de dados |
| Scikit-learn  | Treinamento do modelo |
| FastAPI       | CriaÃ§Ã£o da API REST |
| Uvicorn       | Servidor ASGI |

---

## ğŸ“‚ Estrutura do Projeto


libras-sign-recognition-api/
â”‚
â”œâ”€â”€ coletar_dados.py
â”œâ”€â”€ treinar_modelo.py
â”œâ”€â”€ api.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ dados/ (criado manualmente)


---

## ğŸ§  Ambiente Virtual

Recomenda-se fortemente o uso de um ambiente virtual para:

- Isolar dependÃªncias
- Evitar conflitos com outros projetos
- Garantir que o projeto funcione corretamente em diferentes mÃ¡quinas

---

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1ï¸âƒ£ Clonar o repositÃ³rio

```bash
git clone <URL_DO_REPOSITORIO>
cd libras-sign-recognition-api
2ï¸âƒ£ Criar e ativar ambiente virtual
Windows
python -m venv venv
venv\Scripts\activate
Linux / Mac
python3 -m venv venv
source venv/bin/activate
3ï¸âƒ£ Instalar dependÃªncias
pip install -r requirements.txt
ğŸ“ PreparaÃ§Ã£o do Dataset

Antes de coletar dados, Ã© necessÃ¡rio criar manualmente a pasta:

dados/

Dentro dela, crie uma subpasta para cada letra que deseja treinar:

dados/
   â”œâ”€â”€ A/
   â”œâ”€â”€ B/
   â”œâ”€â”€ C/
   â””â”€â”€ D/

Cada subpasta representa uma classe do modelo.

ğŸ“¸ Coleta de Dados

Execute:

python coletar_dados.py

A webcam serÃ¡ ativada

Posicione a mÃ£o representando a letra desejada

Os dados serÃ£o salvos automaticamente na pasta correspondente

ğŸ§  Treinamento do Modelo

ApÃ³s coletar os dados:

python treinar_modelo.py

Esse processo irÃ¡:

Ler os dados da pasta dados/

Treinar o modelo de classificaÃ§Ã£o

Gerar o arquivo modelo.pkl

ğŸŒ Executando a API
uvicorn api:app --reload

A aplicaÃ§Ã£o ficarÃ¡ disponÃ­vel em:

http://127.0.0.1:8000

DocumentaÃ§Ã£o interativa:

http://127.0.0.1:8000/docs
ğŸ“¤ Exemplo de Resposta
{
  "letra": "D"
}
ğŸ¯ Objetivo do Projeto

Este projeto demonstra:

AplicaÃ§Ã£o prÃ¡tica de VisÃ£o Computacional

Treinamento e utilizaÃ§Ã£o de modelo de Machine Learning

ConstruÃ§Ã£o de API REST com FastAPI

EstruturaÃ§Ã£o organizada de projeto backend

Possibilidade de integraÃ§Ã£o com outras linguagens (ex: Java)

âš ï¸ ObservaÃ§Ãµes

Ã‰ necessÃ¡rio possuir webcam funcional

Boa iluminaÃ§Ã£o melhora a precisÃ£o

A qualidade do modelo depende da quantidade e variedade de dados coletados

ğŸ”® PossÃ­veis EvoluÃ§Ãµes

Expandir para todas as letras do alfabeto

Aumentar o dataset

Melhorar o modelo utilizando redes neurais

Criar interface web para visualizaÃ§Ã£o

Realizar deploy em ambiente de nuvem
